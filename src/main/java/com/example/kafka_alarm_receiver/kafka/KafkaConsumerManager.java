package com.example.kafka_alarm_receiver.kafka;

import com.example.kafka_alarm_receiver.domain.AlarmMessage;
import com.example.kafka_alarm_receiver.domain.KafkaConfig;
import com.example.kafka_alarm_receiver.es.ElasticsearchService;
import com.example.kafka_alarm_receiver.service.KafkaService;
import com.fasterxml.jackson.databind.ObjectMapper;
import jakarta.annotation.PostConstruct;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.kafka.config.ConcurrentKafkaListenerContainerFactory;
import org.springframework.kafka.core.ConsumerFactory;
import org.springframework.kafka.core.DefaultKafkaConsumerFactory;
import org.springframework.kafka.listener.ConcurrentMessageListenerContainer;
import org.springframework.kafka.listener.ContainerProperties;
import org.springframework.kafka.listener.MessageListener;
import org.springframework.stereotype.Component;

import java.util.Map;
import java.util.Optional;
import java.util.Properties;
import java.util.concurrent.ConcurrentHashMap;

@SuppressWarnings("ALL")
@Slf4j
@Component
@RequiredArgsConstructor
public class KafkaConsumerManager implements Observer<KafkaConfig>{

    private final KafkaService kafkaService;
    private final ConcurrentKafkaListenerContainerFactory<String, String> listenerContainerFactory;
    private final ElasticsearchService elasticsearchService;
    private final Map<String, ConcurrentMessageListenerContainer<String, String>> containers = new ConcurrentHashMap<>();
    private final ObjectMapper objectMapper = new ObjectMapper();
    private final ConfigListener listener;
    public void addListener(KafkaConfig config) {
        String topic = config.getTopic();
        String application = config.getName();

        // å¦‚æœè¯¥ topic å·²ç»å­˜åœ¨ç›‘å¬å™¨ï¼Œåˆ™åœæ­¢ä¹‹å‰çš„ç›‘å¬å™¨
        if (containers.containsKey(application)) {
            removeListener(application);
            log.info("âš ï¸ [è·³è¿‡] å·²å­˜åœ¨ç›‘å¬å™¨ï¼Œtopic={}ï¼Œè·³è¿‡åˆ›å»º", topic);
        }

        try {
            // é…ç½®æ¶ˆæ¯ç›‘å¬å™¨
            ContainerProperties containerProps = createContainerProperties(topic, config);
            ConsumerFactory<String, String> consumerFactory = createConsumerFactory(config);

            // åˆ›å»ºå¹¶å¯åŠ¨ Kafka æ¶ˆè´¹è€…ç›‘å¬å®¹å™¨
            startKafkaListener(application, topic, config, containerProps, consumerFactory);
        } catch (Exception e) {
            log.error("ğŸ”¥ [å¤±è´¥] å¯åŠ¨ Kafka ç›‘å¬å™¨å¤±è´¥ | application={} | topic={} | group={}",
                    application, topic, config.getConsumerGroup(), e);
        }
    }

    private ContainerProperties createContainerProperties(String topic, KafkaConfig config) {
        ContainerProperties containerProps = new ContainerProperties(topic);
        containerProps.setMessageListener(createMessageListener(config));
        return containerProps;
    }

    private MessageListener<String, String> createMessageListener(KafkaConfig config) {
        return record -> {
            log.info("ğŸ“¥ [æ¥æ”¶] topic={} | key={} | value={}", record.topic(), record.key(), record.value());
            try {
                AlarmMessage alarmMessage = objectMapper.readValue(record.value(), AlarmMessage.class);
                alarmMessage.setDataResource(config.getDataResource());
                alarmMessage.setAppName(config.getName());
                elasticsearchService.saveAlarm(alarmMessage);
                log.info("âœ… [å†™å…¥ES] å‘Šè­¦æ•°æ®å·²å†™å…¥ç´¢å¼•");
            } catch (Exception e) {
                log.error("âŒ [é”™è¯¯] è§£ææˆ–å†™å…¥ESå¤±è´¥", e);
            }
        };
    }

    private void startKafkaListener(String application, String topic, KafkaConfig config,
                                    ContainerProperties containerProps, ConsumerFactory<String, String> consumerFactory) {
        ConcurrentMessageListenerContainer<String, String> container =
                new ConcurrentMessageListenerContainer<>(consumerFactory, containerProps);
        container.start();
        containers.put(application, container);
        log.info("âœ… [å¯åŠ¨æˆåŠŸ] Kafka ç›‘å¬å™¨å·²å¯åŠ¨ | topic={} | group={}", topic, config.getConsumerGroup());
    }

    public void removeListener(String application) {
        Optional.ofNullable(containers.get(application))
                .ifPresentOrElse(container -> stopListener(application, container),
                        () -> log.warn("âš ï¸ [æ— æ•ˆæ“ä½œ] ç›‘å¬å™¨ {} ä¸å­˜åœ¨ï¼Œæ— æ³•åœæ­¢", application));
    }

    private void stopListener(String application, ConcurrentMessageListenerContainer<String, String> container) {
        try {
            container.stop();
            containers.remove(application);
            log.info("ğŸ›‘ [åœæ­¢] å·²åœæ­¢ç›‘å¬å™¨ï¼š{}", application);
        } catch (Exception e) {
            log.error("ğŸ’¥ [å¼‚å¸¸] åœæ­¢ç›‘å¬å™¨å¤±è´¥ï¼š" + application, e);
        }
    }

    public void removeAllListeners() {
        log.info("ğŸ§¹ [æ¸…ç†] å‡†å¤‡åœæ­¢æ‰€æœ‰ Kafka ç›‘å¬å™¨...");
        containers.forEach(this::stopListener);
        containers.clear();
        log.info("âœ… [å®Œæˆ] æ‰€æœ‰ Kafka ç›‘å¬å™¨å·²æˆåŠŸæ¸…ç†");
    }

    private ConsumerFactory<String, String> createConsumerFactory(KafkaConfig config) {
        Properties properties = kafkaService.createConsumerConfig(config);
        Map<String, Object> configMap = (Map) properties;
        return new DefaultKafkaConsumerFactory<>(configMap);
    }


    @PostConstruct
    public void init() {
        listener.registerObserver(this);
        log.info("ğŸŸ¢ Kafka consumer manager start successfully");
    }

    @Override
    public void onUpdate(KafkaConfig config) {
        log.info("Kafka consumer manager detected a configuration change and updated the consumer.");
        addListener(config);
    }

    @Override
    public void onInit(KafkaConfig config) {
        this.onUpdate(config);
    }
}
